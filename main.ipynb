{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus São Carlos</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Nome**: Fernando Messias da Silva - **RA**: 489450 </br>\n",
    "**Nome**: Josie de Assis Francisco Henriques do Nascimento - **RA**: 840214\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para interpretar e analisar os dados, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Import Packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from nltk import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load csv file\n",
    "\n",
    "#FILES_DIRECTORY = \"/kaggle/input/ufscar-am-2024-projeto-final\"\n",
    "FILES_DIRECTORY = \"dados\"\n",
    "\n",
    "# Liste o conteúdo do diretório\n",
    "conteudo_diretorio = os.listdir(FILES_DIRECTORY)\n",
    "\n",
    "# Imprima o conteúdo do diretório\n",
    "for item in conteudo_diretorio:\n",
    "    print(item)\n",
    "\n",
    "rhp_data = pd.read_csv(os.path.join(FILES_DIRECTORY, \"RHP_data.csv\"), sep=',', encoding='utf-8')\n",
    "train_data = pd.read_csv(os.path.join(FILES_DIRECTORY, \"train.csv\"), sep=',', index_col=None)\n",
    "test_data = pd.read_csv(os.path.join(FILES_DIRECTORY, 'test.csv'), sep=',', index_col=None)\n",
    "rhp_data_classe = pd.merge(rhp_data, train_data, on='Id')\n",
    "#df_rhp_test = pd.merge(df_rhp, df_test, on='Id')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rhp_data_classe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cria um novo dataframe sem os atributos Idade, IMC, Atendimento, Convenio, Sexo, HDA1 e HDA2. Esses atributos são reduntantes ou não são relevantes para a análise a ser feito\n",
    "\n",
    "#columns_to_drop = ['DN', 'IMC', 'Atendimento', 'Convenio', 'Sexo', 'HDA 1', 'HDA2']\n",
    "columns_to_drop = ['DN', 'Atendimento', 'Convenio', 'HDA 1', 'HDA2']\n",
    "rhp_data_processed = rhp_data_classe.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the column structure of the dataset\n",
    "rhp_data_processed.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Contar a distribuição das classes no conjunto de treino\n",
    "class_distribution = rhp_data_processed[\"CLASSE\"].value_counts(dropna=False)\n",
    "\n",
    "# Visualizar a distribuição das classes\n",
    "plt.figure(figsize=(6,4))\n",
    "seaborn.barplot(x=class_distribution.index, y=class_distribution.values, palette=\"coolwarm\")\n",
    "plt.xlabel(\"Classe\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.title(\"Distribuição das Classes no Conjunto de Treinamento\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identifying outliers\n",
    "\n",
    "# Histogram for each attribute:\n",
    "for attribute in rhp_data_processed.columns:\n",
    "    n, bins, patches = plt.hist(rhp_data_processed[attribute], bins=10, color='blue', alpha=0.7, rwidth=0.85)\n",
    "    plt.title(f\"Histograma do Atributo {attribute}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Density chart for each attribute (Help to identify outliers)\n",
    "for attribute in rhp_data_processed.columns:\n",
    "    densityPlot = rhp_data_processed[attribute].plot(kind='density', subplots=True, layout=(1, 1), sharex=False, sharey=False)\n",
    "    plt.title(f\"Gráfico de Densidade do Atributo {attribute}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for null values in the dataset\n",
    "missing_values = rhp_data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# Show attributes with higher count of null values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Análise Estatística\n",
    "# Select only numeric columns\n",
    "numerical_columns = rhp_data_processed.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# Generate descriptive statistics\n",
    "stats_summary = rhp_data_processed[numerical_columns].describe()\n",
    "\n",
    "# Display the summary\n",
    "display(stats_summary)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution plot\n",
    "# Main numeric variables plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "seaborn.histplot(rhp_data_processed[\"Peso\"].dropna(), bins=50, kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Distribuição do Peso\")\n",
    "\n",
    "seaborn.histplot(rhp_data_processed[\"Altura\"].dropna(), bins=50, kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Distribuição da Altura\")\n",
    "\n",
    "seaborn.histplot(rhp_data_processed[\"IMC\"].dropna(), bins=50, kde=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Distribuição do IMC\")\n",
    "\n",
    "seaborn.histplot(rhp_data_processed[\"PA SISTOLICA\"].dropna(), bins=50, kde=True, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Distribuição da Pressão Sistólica\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Matrix\n",
    "# Calcular a matriz de correlação entre as variáveis numéricas\n",
    "correlation_matrix = rhp_data_processed[numerical_columns].corr()\n",
    "\n",
    "# Gerar um mapa de calor para visualização das correlações\n",
    "plt.figure(figsize=(10, 8))\n",
    "seaborn.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlação entre Variáveis Numéricas\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verificar a distribuição das classes no conjunto de treinamento\n",
    "class_distribution = rhp_data_processed['CLASSE'].value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "class_distribution",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rhp_data_processed = rhp_data_processed.dropna(subset=['CLASSE'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pulsos_distribution = rhp_data_processed['PULSOS'].value_counts(normalize=True)\n",
    "ppa_distribution = rhp_data_processed['PPA'].value_counts(normalize=True)\n",
    "b2_distribution = rhp_data_processed['B2'].value_counts(normalize=True)\n",
    "sopro_distribution = rhp_data_processed['SOPRO'].value_counts(normalize=True)\n",
    "sexo_distribution = rhp_data_processed['SEXO'].value_counts(normalize=True)\n",
    "motivo1_distribution = rhp_data_processed['MOTIVO1'].value_counts(normalize=True)\n",
    "motivo2_distribution = rhp_data_processed['MOTIVO2'].value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pulsos_distribution,ppa_distribution,b2_distribution,sopro_distribution,sexo_distribution,motivo1_distribution,motivo2_distribution",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace #VALUE! to NaN\n",
    "rhp_data_processed.replace(\"#VALUE!\", pd.NA, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['SEXO'] = rhp_data_processed['SEXO'].replace({\n",
    "    'Masculino': '1',\n",
    "    'M':'1',\n",
    "    'F':'0',\n",
    "    'Feminino': '0',\n",
    "    'masculino': '1',\n",
    "    'feminino': '0',\n",
    "    'Indeterminado': '-1'\n",
    "}).astype('Int64')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['PULSOS'] = rhp_data_processed['PULSOS'].replace({\n",
    "    'Normais': '0',\n",
    "    'NORMAIS': '0',\n",
    "    'Amplos': '1',\n",
    "    'AMPLOS': '1',\n",
    "    'Outro': '3',\n",
    "    'Femorais Diminuidos': '2',\n",
    "    'Femorais diminuidos': '2',\n",
    "    'Diminuídos':'2',\n",
    "    'Diminuídos ':'2'\n",
    "}).astype('Int64')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['PPA'] = rhp_data_processed['PPA'].replace({\n",
    "    'Não Calculado': '-1',\n",
    "    'Normal': '0',\n",
    "    '#VALUE!': '-1',\n",
    "    'Pre-Hipertensão PAD': '1',\n",
    "    'HAS-2 PAS':'2',\n",
    "    'Pre-Hipertensão PAS':'3',\n",
    "    'HAS-1 PAS':'4',\n",
    "    'HAS-1 PAD':'5',\n",
    "    'HAS-2 PAD':'6'\n",
    "}).astype('Int64')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['B2'] = rhp_data_processed['B2'].replace({\n",
    "    'Normal': '0',\n",
    "    'Hiperfonética': '1',\n",
    "    'Desdob fixo': '2',\n",
    "    'Desdob Fixo': '2',\n",
    "    'Outro': '3',\n",
    "    'Única': '0'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['SOPRO'] = rhp_data_processed['SOPRO'].replace({\n",
    "    'ausente': '0',\n",
    "    'Sistólico': '1',\n",
    "    'sistólico': '1',\n",
    "    'contínuo': '2',\n",
    "    'Contínuo': '2',\n",
    "    'diastólico': '3',\n",
    "    'Sistolico e diastólico': '4',\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['MOTIVO1'] = rhp_data_processed['MOTIVO1'].replace({\n",
    "    '5 - Parecer cardiológico': '5',\n",
    "    '6 - Suspeita de cardiopatia': '6',\n",
    "    '1 - Cardiopatia já estabelecida': '1',\n",
    "    '2 - Check-up': '2',\n",
    "    '7 - Outro': '7'\n",
    "}).astype('Int64')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['MOTIVO2'] = rhp_data_processed['MOTIVO2'].replace({\n",
    "    '5 - Cirurgia': '5',\n",
    "    '6 - Sopro': '6',\n",
    "    '1 - Cardiopatia congenica': '1',\n",
    "    'Outro ': '7',\n",
    "    'Outro': '7',\n",
    "    '5 - Atividade física': '5',\n",
    "    '6 - Dor precordial': '6',\n",
    "    '6 - Palpitação/taquicardia/arritmia': '6',\n",
    "    '6 - HAS/dislipidemia/obesidade': '6',\n",
    "    '6 - Dispnéia': '6',\n",
    "    '6 - Cianose': '6',\n",
    "    '1 - Cardiopatia adquirida': '1',\n",
    "    '6 - Cardiopatia na familia': '6',\n",
    "    '6 - Cansaço': '6',\n",
    "    '5 - Uso de cisaprida': '5',\n",
    "    '6 - Alterações de pulso/perfusão': '6',\n",
    "    '6 - Cianose e dispnéia': '6'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed['CLASSE'] = rhp_data_processed['CLASSE'].replace({\n",
    "    'Normal': '0',\n",
    "    'Normais': '0',\n",
    "    'Anormal': '1'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rhp_data_processed.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed_normalized = rhp_data_processed\n",
    "rhp_data_processed_normalized['Peso'] = pd.to_numeric(rhp_data_processed_normalized['Peso'], errors='coerce')\n",
    "rhp_data_processed_normalized['Altura'] = pd.to_numeric(rhp_data_processed_normalized['Altura'], errors='coerce')\n",
    "rhp_data_processed_normalized['IMC'] = pd.to_numeric(rhp_data_processed_normalized['IMC'], errors='coerce')\n",
    "rhp_data_processed_normalized['IDADE'] = pd.to_numeric(rhp_data_processed_normalized['IDADE'], errors='coerce')\n",
    "rhp_data_processed_normalized['PULSOS'] = pd.to_numeric(rhp_data_processed_normalized['PULSOS'], errors='coerce')\n",
    "rhp_data_processed_normalized['PA SISTOLICA'] = pd.to_numeric(rhp_data_processed_normalized['PA SISTOLICA'], errors='coerce')\n",
    "rhp_data_processed_normalized['PA DIASTOLICA'] = pd.to_numeric(rhp_data_processed_normalized['PA DIASTOLICA'], errors='coerce')\n",
    "rhp_data_processed_normalized['PPA'] = pd.to_numeric(rhp_data_processed_normalized['PPA'], errors='coerce')\n",
    "rhp_data_processed_normalized['B2'] = pd.to_numeric(rhp_data_processed_normalized['B2'], errors='coerce')\n",
    "rhp_data_processed_normalized['FC'] = pd.to_numeric(rhp_data_processed_normalized['FC'], errors='coerce')\n",
    "rhp_data_processed_normalized['SEXO'] = pd.to_numeric(rhp_data_processed_normalized['SEXO'], errors='coerce')\n",
    "rhp_data_processed_normalized['MOTIVO1'] = pd.to_numeric(rhp_data_processed_normalized['MOTIVO1'], errors='coerce')\n",
    "rhp_data_processed_normalized['MOTIVO2'] = pd.to_numeric(rhp_data_processed_normalized['MOTIVO2'], errors='coerce')\n",
    "rhp_data_processed_normalized['SOPRO'] = pd.to_numeric(rhp_data_processed_normalized['SOPRO'], errors='coerce')\n",
    "rhp_data_processed_normalized['CLASSE'] = pd.to_numeric(rhp_data_processed_normalized['CLASSE'], errors='coerce')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rhp_data_processed_normalized['Peso'].fillna(rhp_data_processed_normalized['Peso'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['Altura'].fillna(rhp_data_processed_normalized['Altura'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['IMC'].fillna(rhp_data_processed_normalized['IMC'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['IDADE'].fillna(rhp_data_processed_normalized['IDADE'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['PULSOS'].fillna(rhp_data_processed_normalized['PULSOS'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['PA SISTOLICA'].fillna(rhp_data_processed_normalized['PA SISTOLICA'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['PA DIASTOLICA'].fillna(rhp_data_processed_normalized['PA DIASTOLICA'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['PPA'].fillna(rhp_data_processed_normalized['PPA'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['B2'].fillna(rhp_data_processed_normalized['B2'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['FC'].fillna(rhp_data_processed_normalized['FC'].median(), inplace=True)\n",
    "rhp_data_processed_normalized['SEXO'].fillna(rhp_data_processed_normalized['SEXO'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['MOTIVO1'].fillna(rhp_data_processed_normalized['MOTIVO1'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['MOTIVO2'].fillna(rhp_data_processed_normalized['MOTIVO2'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['SOPRO'].fillna(rhp_data_processed_normalized['SOPRO'].mode()[0], inplace=True)\n",
    "rhp_data_processed_normalized['CLASSE'].fillna(rhp_data_processed_normalized['CLASSE'].median(), inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização (Z-score) aos atributos numéricos\n",
    "numerical_columns = [\"IDADE\", \"Peso\", \"Altura\", \"IMC\", \"PA SISTOLICA\", \"PA DIASTOLICA\", \"FC\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular a média e desvio padrão de cada atributo\n",
    "means = rhp_data_processed_normalized[numerical_columns].mean()\n",
    "stds = rhp_data_processed_normalized[numerical_columns].std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização\n",
    "rhp_data_processed_normalized[numerical_columns] = (rhp_data_processed_normalized[numerical_columns] - means) / stds\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rhp_data_processed_normalized.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salvar dados pre-processados\n",
    "rhp_data_processed_normalized.to_csv('dados/rhp_data_processed_normalized.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais padrões e testando diferentes modelos."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cria o arquivo de treinamento\n",
    "train_dataset = train_data.merge(rhp_data_processed_normalized, on=\"Id\", how=\"left\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset = train_dataset.drop(columns=[\"CLASSE_x\"]).rename(columns={\"CLASSE_y\": \"CLASSE\"})",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove NaN from train dataset\n",
    "train_dataset['Peso'].fillna(train_dataset['Peso'].median(), inplace=True)\n",
    "train_dataset['Altura'].fillna(train_dataset['Altura'].median(), inplace=True)\n",
    "train_dataset['IMC'].fillna(train_dataset['IMC'].median(), inplace=True)\n",
    "train_dataset['IDADE'].fillna(train_dataset['IDADE'].median(), inplace=True)\n",
    "train_dataset['PULSOS'].fillna(train_dataset['PULSOS'].mode()[0], inplace=True)\n",
    "train_dataset['PA SISTOLICA'].fillna(train_dataset['PA SISTOLICA'].median(), inplace=True)\n",
    "train_dataset['PA DIASTOLICA'].fillna(train_dataset['PA DIASTOLICA'].median(), inplace=True)\n",
    "train_dataset['PPA'].fillna(train_dataset['PPA'].mode()[0], inplace=True)\n",
    "train_dataset['B2'].fillna(train_dataset['B2'].mode()[0], inplace=True)\n",
    "train_dataset['FC'].fillna(train_dataset['FC'].median(), inplace=True)\n",
    "train_dataset['SEXO'].fillna(train_dataset['SEXO'].mode()[0], inplace=True)\n",
    "train_dataset['MOTIVO1'].fillna(train_dataset['MOTIVO1'].mode()[0], inplace=True)\n",
    "train_dataset['MOTIVO2'].fillna(train_dataset['MOTIVO2'].median(), inplace=True)\n",
    "train_dataset['SOPRO'].fillna(train_dataset['SOPRO'].mode()[0], inplace=True)\n",
    "train_dataset['CLASSE'].fillna(train_dataset['CLASSE'].median(), inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização (Z-score) aos atributos numéricos\n",
    "numerical_columns = [\"IDADE\", \"Peso\", \"Altura\", \"IMC\", \"PA SISTOLICA\", \"PA DIASTOLICA\", \"FC\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular a média e desvio padrão de cada atributo\n",
    "means = train_dataset[numerical_columns].mean()\n",
    "stds = train_dataset[numerical_columns].std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização\n",
    "train_dataset[numerical_columns] = (train_dataset[numerical_columns] - means) / stds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salvar dados pre-processados\n",
    "train_dataset.to_csv('dados/train_dataset.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Começar a aplicar os algoritmos para fazer o treinamento\n",
    "X = train_dataset.drop(['CLASSE', 'Id'], axis=1)\n",
    "X.fillna(0)\n",
    "y = train_dataset['CLASSE']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dividir em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar SMOTE para balancear as classes\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train.astype(int), y_train.astype(int))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dicionário para armazenar resultados\n",
    "results = {}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Treinar modelo\n",
    "# k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "knn.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_knn = knn.predict_proba(X_val)[:, 1]\n",
    "results['k-NN'] = roc_auc_score(y_val, y_pred_knn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Treinar modelo\n",
    "# RandomForest\n",
    "randomForest = RandomForestClassifier(n_estimators=750, max_depth=20, min_samples_split=5, random_state=42)\n",
    "randomForest.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_random_forest = randomForest.predict_proba(X_val)[:, 1]\n",
    "results['Radom Forest'] = roc_auc_score(y_val, y_pred_random_forest)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Treinar modelo\n",
    "# Logistic Regression\n",
    "logisticRegression = LogisticRegression(max_iter=750)\n",
    "logisticRegression.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_logistic_regression = logisticRegression.predict_proba(X_val)[:, 1]\n",
    "results['Logistic Regression'] = roc_auc_score(y_val, y_pred_logistic_regression)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb_calibrated = CalibratedClassifierCV(nb, method=\"sigmoid\")\n",
    "nb_calibrated.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_nb = nb_calibrated.predict_proba(X_val)[:, 1]\n",
    "results['Naive Bayes'] = roc_auc_score(y_val, y_pred_nb)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=750, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "gb.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_gb = gb.predict_proba(X_val)[:, 1]\n",
    "results['Gradient Boosting'] = roc_auc_score(y_val, y_pred_gb)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_svm = svm.predict_proba(X_val)[:, 1]\n",
    "results['SVM'] = roc_auc_score(y_val, y_pred_svm)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Redes Neurais\n",
    "mlp = MLPClassifier(random_state=42, max_iter=10000)\n",
    "mlp.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_mlp = mlp.predict_proba(X_val)[:, 1]\n",
    "results['Redes Neurais'] = roc_auc_score(y_val, y_pred_mlp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definir o grid de hiperparâmetros\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decision Tree\n",
    "dt = tree.DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "dt.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_dt = dt.predict_proba(X_val)[:, 1]\n",
    "results['Decision Tree'] = roc_auc_score(y_val, y_pred_dt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_gs = grid_search.predict_proba(X_val)[:, 1]\n",
    "results['Grid Search'] = roc_auc_score(y_val, y_pred_gs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filtrar os dados de teste baseados nos IDs do test.csv\n",
    "test_filtered = test_data.merge(rhp_data, on=\"Id\", how=\"left\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remove columns dropped during training phase\n",
    "test_filtered = test_filtered.drop(columns=columns_to_drop, errors='ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['SEXO'] = test_filtered['SEXO'].replace({\n",
    "    'Masculino': '1',\n",
    "    'M':'1',\n",
    "    'F':'0',\n",
    "    'Feminino': '0',\n",
    "    'masculino': '1',\n",
    "    'feminino': '0',\n",
    "    'Indeterminado': '-1'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['PULSOS'] = test_filtered['PULSOS'].replace({\n",
    "    'Normais': '0',\n",
    "    'Amplos': '1',\n",
    "    'Outro': '3',\n",
    "    'Femorais Diminuidos': '2',\n",
    "    'Diminuídos':'2',\n",
    "    'Diminuídos ':'2',\n",
    "    'Femorais diminuidos':'2'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['PPA'] = test_filtered['PPA'].replace({\n",
    "    'Não Calculado': '-1',\n",
    "    'Normal': '0',\n",
    "    '#VALUE!': '-1',\n",
    "    'Pre-Hipertensão PAD': '1',\n",
    "    'HAS-2 PAS':'2',\n",
    "    'Pre-Hipertensão PAS':'3',\n",
    "    'HAS-1 PAS':'4',\n",
    "    'HAS-1 PAD':'5',\n",
    "    'HAS-2 PAD':'6'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['B2'] = test_filtered['B2'].replace({\n",
    "    'Normal': '0',\n",
    "    'Hiperfonética': '1',\n",
    "    'Desdob fixo': '2',\n",
    "    'Desdob Fixo': '2',\n",
    "    'Outro': '3',\n",
    "    'Única': '0'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['SOPRO'] = test_filtered['SOPRO'].replace({\n",
    "    'ausente': '0',\n",
    "    'Sistólico': '1',\n",
    "    'sistólico': '1',\n",
    "    'contínuo': '2',\n",
    "    'Contínuo': '2',\n",
    "    'diastólico': '3',\n",
    "    'Sistolico e diastólico': '4',\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['MOTIVO1'] = test_filtered['MOTIVO1'].replace({\n",
    "    '5 - Parecer cardiológico': '5',\n",
    "    '6 - Suspeita de cardiopatia': '6',\n",
    "    '1 - Cardiopatia já estabelecida': '1',\n",
    "    '2 - Check-up': '2',\n",
    "    '7 - Outro': '7'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['MOTIVO2'] = test_filtered['MOTIVO2'].replace({\n",
    "    '5 - Cirurgia': '5',\n",
    "    '6 - Sopro': '6',\n",
    "    '1 - Cardiopatia congenica': '1',\n",
    "    'Outro ': '7',\n",
    "    'Outro': '7',\n",
    "    '5 - Atividade física': '5',\n",
    "    '6 - Dor precordial': '6',\n",
    "    '6 - Palpitação/taquicardia/arritmia': '6',\n",
    "    '6 - HAS/dislipidemia/obesidade': '6',\n",
    "    '6 - Dispnéia': '6',\n",
    "    '6 - Cianose': '6',\n",
    "    '1 - Cardiopatia adquirida': '1',\n",
    "    '6 - Cardiopatia na familia': '6',\n",
    "    '6 - Cansaço': '6',\n",
    "    '5 - Uso de cisaprida': '5',\n",
    "    '6 - Alterações de pulso/perfusão': '6',\n",
    "    '6 - Cianose e dispnéia': '6'\n",
    "}).astype('Int64')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['Peso'] = pd.to_numeric(test_filtered['Peso'], errors='coerce')\n",
    "test_filtered['Altura'] = pd.to_numeric(test_filtered['Altura'], errors='coerce')\n",
    "test_filtered['IMC'] = pd.to_numeric(test_filtered['IMC'], errors='coerce')\n",
    "test_filtered['IDADE'] = pd.to_numeric(test_filtered['IDADE'], errors='coerce')\n",
    "test_filtered['PULSOS'] = pd.to_numeric(test_filtered['PULSOS'], errors='coerce')\n",
    "test_filtered['PA SISTOLICA'] = pd.to_numeric(test_filtered['PA SISTOLICA'], errors='coerce')\n",
    "test_filtered['PA DIASTOLICA'] = pd.to_numeric(test_filtered['PA DIASTOLICA'], errors='coerce')\n",
    "test_filtered['PPA'] = pd.to_numeric(test_filtered['PPA'], errors='coerce')\n",
    "test_filtered['B2'] = pd.to_numeric(test_filtered['B2'], errors='coerce')\n",
    "test_filtered['FC'] = pd.to_numeric(test_filtered['FC'], errors='coerce')\n",
    "test_filtered['SEXO'] = pd.to_numeric(test_filtered['SEXO'], errors='coerce')\n",
    "test_filtered['MOTIVO1'] = pd.to_numeric(test_filtered['MOTIVO1'], errors='coerce')\n",
    "test_filtered['MOTIVO2'] = pd.to_numeric(test_filtered['MOTIVO2'], errors='coerce')\n",
    "test_filtered['SOPRO'] = pd.to_numeric(test_filtered['SOPRO'], errors='coerce')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_filtered['Peso'].fillna(test_filtered['Peso'].median(), inplace=True)\n",
    "test_filtered['Altura'].fillna(test_filtered['Altura'].median(), inplace=True)\n",
    "test_filtered['IMC'].fillna(test_filtered['IMC'].median(), inplace=True)\n",
    "test_filtered['IDADE'].fillna(test_filtered['IDADE'].median(), inplace=True)\n",
    "test_filtered['PULSOS'].fillna(test_filtered['PULSOS'].mode()[0], inplace=True)\n",
    "test_filtered['PA SISTOLICA'].fillna(test_filtered['PA SISTOLICA'].median(), inplace=True)\n",
    "test_filtered['PA DIASTOLICA'].fillna(test_filtered['PA DIASTOLICA'].median(), inplace=True)\n",
    "test_filtered['PPA'].fillna(test_filtered['PPA'].mode()[0], inplace=True)\n",
    "test_filtered['B2'].fillna(test_filtered['B2'].mode()[0], inplace=True)\n",
    "test_filtered['FC'].fillna(test_filtered['FC'].median(), inplace=True)\n",
    "test_filtered['SEXO'].fillna(test_filtered['SEXO'].mode()[0], inplace=True)\n",
    "test_filtered['MOTIVO1'].fillna(test_filtered['MOTIVO1'].mode()[0], inplace=True)\n",
    "test_filtered['MOTIVO2'].fillna(test_filtered['MOTIVO2'].mode()[0], inplace=True)\n",
    "test_filtered['SOPRO'].fillna(test_filtered['SOPRO'].mode()[0], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização (Z-score) aos atributos numéricos\n",
    "numerical_columns = [\"IDADE\", \"Peso\", \"Altura\", \"IMC\", \"PA SISTOLICA\", \"PA DIASTOLICA\", \"FC\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular a média e desvio padrão de cada atributo\n",
    "means = test_filtered[numerical_columns].mean()\n",
    "stds = test_filtered[numerical_columns].std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aplicar a padronização\n",
    "test_filtered[numerical_columns] = (test_filtered[numerical_columns] - means) / stds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Remover a coluna CLASSE do conjunto de teste, pois essa é a variável a ser predita\n",
    "if \"CLASSE\" in test_filtered.columns:\n",
    "    test_filtered = test_filtered.drop(columns=[\"CLASSE\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separar features (X) e rótulos (y) do conjunto de treinamento\n",
    "X_train = train_data.drop(columns=[\"Id\", \"CLASSE\"])\n",
    "y_train = train_data[\"CLASSE\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Features do conjunto de teste\n",
    "X_test = test_filtered.drop(columns=[\"Id\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_test",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verificar as dimensões dos conjuntos\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fazer previsões no conjunto de teste\n",
    "pred_knn = knn.predict_proba(X_test)\n",
    "pred_nb = nb_calibrated.predict_proba(X_test)\n",
    "pred_svm = svm.predict_proba(X_test)\n",
    "pred_mlp = mlp.predict_proba(X_test)\n",
    "pred_rf = randomForest.predict_proba(X_test)\n",
    "pred_lr = logisticRegression.predict_proba(X_test)\n",
    "pred_gb = gb.predict_proba(X_test)\n",
    "pred_dt = dt.predict_proba(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pred_knn",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Criar um DataFrame para armazenar os resultados\n",
    "results = test_filtered[[\"Id\"]].copy()\n",
    "results[\"k-NN\"] = pred_knn[:, 1]\n",
    "results[\"Naive Bayes\"] = pred_nb[:, 1]\n",
    "results[\"SVM\"] = pred_svm[:, 1]\n",
    "results[\"Redes Neurais\"] = pred_mlp[:, 1]\n",
    "results[\"Random Forest\"] = pred_rf[:, 1]\n",
    "results[\"Logistic Regression\"] = pred_lr[:, 1]\n",
    "results[\"Gradient Boosting\"] = pred_gb[:, 1]\n",
    "results[\"Decision Tree\"] = pred_dt[:, 1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gera os arquivos de submissão\n",
    "\n",
    "# Criar DataFrame para submissão\n",
    "submission_naive_bayes = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Naive Bayes\"]\n",
    "})\n",
    "\n",
    "submission_knn = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"k-NN\"]\n",
    "})\n",
    "\n",
    "submission_redes_neurais = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Redes Neurais\"]\n",
    "})\n",
    "\n",
    "submission_random_forest = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Random Forest\"]\n",
    "})\n",
    "\n",
    "submission_logistic_regression = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Logistic Regression\"]\n",
    "})\n",
    "\n",
    "submission_gradient_boosting = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Gradient Boosting\"]\n",
    "})\n",
    "\n",
    "submission_decision_tree = pd.DataFrame({\n",
    "    'Id': results[\"Id\"],\n",
    "    'Predicted': results[\"Decision Tree\"]\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salvar o arquivo\n",
    "submission_naive_bayes.to_csv(\"dados/submission_naive_bayes.csv\", index=False)\n",
    "submission_redes_neurais.to_csv(\"dados/submission_redes_neurais.csv\", index=False)\n",
    "submission_knn.to_csv(\"dados/submission_knn.csv\", index=False)\n",
    "submission_random_forest.to_csv(\"dados/random_forest.csv\", index=False)\n",
    "submission_logistic_regression.to_csv(\"dados/logistic_regression.csv\", index=False)\n",
    "submission_gradient_boosting.to_csv(\"dados/gradient_boosting.csv\", index=False)\n",
    "submission_decision_tree.to_csv(\"dados/decision_tree.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos através de tabelas e gráficos, comparados e profundamente analisados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
